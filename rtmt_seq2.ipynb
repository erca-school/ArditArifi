{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24932264-0d7b-4259-8f9b-640f96998c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/ArditArifi'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ffbd168-abf2-4edb-be2a-d9ef0a4ce8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path=\"/home/jovyan/prepared-data/POLAR_EMISS_DATA/CMIP6\"\n",
    "output_path=\"/home/jovyan/student-storages/GROUP3/ArditArifi/output\"\n",
    "\n",
    "! mkdir -p output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c85f27-ff25-42a2-9ca0-bb121df590fe",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e67ddf2-f292-4d0b-9b98-083d8091e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# ANALYSIS\n",
    "import xarray as xr\n",
    "import pandas as p\n",
    "import numpy as np\n",
    "# PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.colors as colors\n",
    "# USER \n",
    "import area_weight as aw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "488b9fc7-8c70-4e2d-bcb1-5f91020363a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# REGIONS\n",
    "region_label = [\"ARC\", \"ANT\"]\n",
    "arctic_lat = [60, 90]\n",
    "antarctic_lat = [-90, -60]\n",
    "\n",
    "# SEASONS\n",
    "seasons_label = [\"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "seasons = {\n",
    "    \"DJF\": [12, 1, 2],   # Dec, Jan, Feb\n",
    "    \"MAM\": [3, 4, 5],    # Mar, Apr, May\n",
    "    \"JJA\": [6, 7, 8],    # Jun, Jul, Aug\n",
    "    \"SON\": [9, 10, 11],  # Sep, Oct, Nov\n",
    "}\n",
    "\n",
    "# Create combined region-season labels\n",
    "region_season_label = [f\"{region} {season}\" for region in region_label for season in seasons_label]\n",
    "\n",
    "# EXPERIMENTS\n",
    "experiments = [\"2xss\"]#, \"2xdust\", \"2xfire\", \"2xDMS\"]\n",
    "\n",
    "# MODELS\n",
    "models = [\"IPSL-CM6A-LR-INCA\", \"UKESM1-0-LL\", \"NorESM2-LM\"]\n",
    "\n",
    "# PATTERN FUNCTION\n",
    "patter = lambda model, var, exp: f\"{source_path}/{var}*{model}*-{exp}*.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86748cc9-b75d-48bf-97f9-c5edc30abe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTRUCT TABLE\n",
    "mean_values = np.full(\n",
    "    shape=(len(region_season_label), len(experiments), len(models)),\n",
    "    fill_value=np.nan\n",
    ")\n",
    "std_values = np.full(\n",
    "    shape=(len(region_season_label), len(experiments), len(models)),\n",
    "    fill_value=np.nan\n",
    ")\n",
    "\n",
    "\n",
    "# LOAD DATA\n",
    "model = \"\"\n",
    "var = \"rtmt\"\n",
    "weight_function = aw.area_weight_haversine\n",
    "\n",
    "# Calculate total steps for progress\n",
    "total_steps = len(models) * len(experiments) * len(seasons_label)\n",
    "current_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c15a9b-1c36-4a79-91bc-1fe32c303dc7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1/12 -> 8.33%\n",
      "0.1760444846214725\n",
      "-0.33843733467809894\n",
      "Progress: 2/12 -> 16.67%\n",
      "-0.27108387318322547\n",
      "-0.07892540282463568\n",
      "Progress: 3/12 -> 25.00%\n",
      "-0.4867704097039545\n",
      "0.014462311218400779\n",
      "Progress: 4/12 -> 33.33%\n",
      "-0.10809622689804982\n",
      "-0.024917476263721\n",
      "Progress: 5/12 -> 41.67%\n",
      "-0.3314394852181358\n",
      "-0.3736942795446541\n",
      "Progress: 6/12 -> 50.00%\n",
      "0.14247118344685075\n",
      "-0.18367146334947282\n",
      "Progress: 7/12 -> 58.33%\n",
      "-0.23740043691358328\n",
      "0.0899258598975459\n",
      "Progress: 8/12 -> 66.67%\n",
      "-0.08501090363067462\n",
      "-0.31398046627966114\n",
      "Progress: 9/12 -> 75.00%\n",
      "-0.6142359111554327\n",
      "-1.0149925489307943\n",
      "Progress: 10/12 -> 83.33%\n",
      "-0.16232835782899752\n",
      "-0.25854572717065183\n",
      "Progress: 11/12 -> 91.67%\n",
      "-0.298342368100128\n",
      "-0.1189752583983575\n",
      "Progress: 12/12 -> 100.00%\n",
      "-0.13904817291858132\n",
      "-0.59636298166125\n",
      "Shape of mean_values: (8, 1, 3)\n",
      "[[[ 0.17604448 -0.33143949 -0.61423591]]\n",
      "\n",
      " [[-0.27108387  0.14247118 -0.16232836]]\n",
      "\n",
      " [[-0.48677041 -0.23740044 -0.29834237]]\n",
      "\n",
      " [[-0.10809623 -0.0850109  -0.13904817]]\n",
      "\n",
      " [[-0.33843733 -0.37369428 -1.01499255]]\n",
      "\n",
      " [[-0.0789254  -0.18367146 -0.25854573]]\n",
      "\n",
      " [[ 0.01446231  0.08992586 -0.11897526]]\n",
      "\n",
      " [[-0.02491748 -0.31398047 -0.59636298]]]\n"
     ]
    }
   ],
   "source": [
    "# MAIN LOOP\n",
    "for idx_model, model in enumerate(models):\n",
    "    print('hi')\n",
    "    try:\n",
    "        # Open control dataset for this model\n",
    "        ds_ctl = xr.open_mfdataset(patter(model, var, \"control\"), combine=\"by_coords\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening control files {patter(model, var, 'control')}: {e}\")\n",
    "        # Skip all seasons for this model if control is missing\n",
    "        current_step += len(seasons_label) * len(experiments)\n",
    "        continue\n",
    "    \n",
    "    for idx_exp, exp in enumerate(experiments):\n",
    "        # Try opening the experiment dataset\n",
    "        try:\n",
    "            ds_exp = xr.open_mfdataset(patter(model, var, exp), combine=\"by_coords\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening experiment files {patter(model, var, exp)}: {e}\")\n",
    "            current_step += len(seasons_label)\n",
    "            continue\n",
    "\n",
    "        # Compute bias as experiment minus control\n",
    "        ds_bias = ds_exp[var] - ds_ctl[var]\n",
    "\n",
    "        for idx_season, season in enumerate(seasons_label):\n",
    "            # Increment progress\n",
    "            current_step += 1\n",
    "            pct = (current_step / total_steps) * 100\n",
    "            print(f\"Progress: {current_step}/{total_steps} -> {pct:.2f}%\")\n",
    "\n",
    "            # 1) Select months for this season\n",
    "            ds_season = ds_bias.sel(time=ds_bias.time.dt.month.isin(seasons[season]))\n",
    "\n",
    "            # ---------------------\n",
    "            # ARCTIC\n",
    "            # ---------------------\n",
    "            ds_season_arctic = ds_season.sel(\n",
    "                lat=slice(arctic_lat[0], arctic_lat[1]),\n",
    "            )\n",
    "            # First, take time mean (removes the 'time' dimension)\n",
    "            ds_arctic_time_mean = ds_season_arctic.mean(dim=\"time\")\n",
    "\n",
    "            # Define weights after subsetting region\n",
    "            weights_arctic_2d = aw.area_weight_haversine( ds_season_arctic.lat.values , ds_season_arctic.lon.values  )\n",
    "            ds_arctic_time_mean = ds_arctic_time_mean * weights_arctic_2d\n",
    "            \n",
    "            # Now do the weighted mean/std over lat/lon\n",
    "            arc_mean = ds_arctic_time_mean.mean(dim=(\"lat\",\"lon\")).values\n",
    "            arc_std  = ds_arctic_time_mean.std(dim=(\"lat\",\"lon\")).values\n",
    "            print(arc_mean)\n",
    "\n",
    "            mean_values[idx_season, idx_exp, idx_model] = arc_mean\n",
    "            std_values[idx_season, idx_exp, idx_model]  = arc_std\n",
    "            \n",
    "            # ---------------------\n",
    "            # ANTARCTIC\n",
    "            # ---------------------\n",
    "            ds_season_antarctic = ds_season.sel(\n",
    "                lat=slice(antarctic_lat[0], antarctic_lat[1]),\n",
    "            )\n",
    "            # Time mean first\n",
    "            ds_antarctic_time_mean = ds_season_antarctic.mean(dim=\"time\")\n",
    "\n",
    "            # Define weights after subsetting region\n",
    "            weights_antarctic_2d = aw.area_weight_haversine( ds_season_antarctic.lat.values , ds_season_antarctic.lon.values  )\n",
    "            ds_antarctic_time_mean = ds_antarctic_time_mean * weights_antarctic_2d\n",
    "\n",
    "            ant_mean = ds_antarctic_time_mean.mean(dim=(\"lat\",\"lon\")).values\n",
    "            ant_std  = ds_antarctic_time_mean.std(dim=(\"lat\",\"lon\")).values\n",
    "\n",
    "            mean_values[idx_season + 4, idx_exp, idx_model] = ant_mean\n",
    "            print(ant_mean)\n",
    "            std_values[idx_season + 4, idx_exp, idx_model]  = ant_std\n",
    "            \n",
    "# Finally, display the populated array\n",
    "print(\"Shape of mean_values:\", mean_values.shape)\n",
    "print(mean_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d490a4b8-0379-4dc3-9f78-de89980d90ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 2xss\n",
      "                    ARC DJF   ARC MAM   ARC JJA   ARC SON   ANT DJF   ANT MAM  \\\n",
      "IPSL-CM6A-LR-INCA  0.176044 -0.271084 -0.486770 -0.108096 -0.338437 -0.078925   \n",
      "UKESM1-0-LL       -0.331439  0.142471 -0.237400 -0.085011 -0.373694 -0.183671   \n",
      "NorESM2-LM        -0.614236 -0.162328 -0.298342 -0.139048 -1.014993 -0.258546   \n",
      "\n",
      "                    ANT JJA   ANT SON  \n",
      "IPSL-CM6A-LR-INCA  0.014462 -0.024917  \n",
      "UKESM1-0-LL        0.089926 -0.313980  \n",
      "NorESM2-LM        -0.118975 -0.596363  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bias = mean_values\n",
    "for idx_exp in range(len(experiments)):\n",
    "    # This will skip the control experiment at index 0\n",
    "    exp_name = experiments[idx_exp]\n",
    "    print(\"Experiment:\", exp_name)\n",
    "    \n",
    "    # bias[:, idx_exp, :].shape -> (len(region_season_label), len(models))\n",
    "    # bias[:, idx_exp, :].transpose().shape -> (len(models), len(region_season_label))\n",
    "    # We want models as rows and region_season_label as columns\n",
    "    df = pd.DataFrame(\n",
    "        data=bias[:, idx_exp, :].transpose(),\n",
    "        index=models,\n",
    "        columns=region_season_label\n",
    "    )\n",
    "\n",
    "    print(df)\n",
    "    print()  # Blank line for readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1da6485-e42b-4646-98f4-70e876f9899d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: 2xss\n",
      "Experiment: 2xdust\n",
      "Experiment: 2xfire\n",
      "Experiment: 2xDMS\n",
      "CSV file saved: all_bias_results.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Suppose the below variables are already defined\n",
    "# bias : shape (len(region_season_label), len(experiments)-1, len(models))\n",
    "# region_season_label : list of region/season names\n",
    "# experiments : list of experiments, with experiment[0] = \"control\"\n",
    "# models : list of model names\n",
    "\n",
    "all_data = []  # Will hold the melted DataFrame for each experiment\n",
    "\n",
    "for idx_exp in range(len(experiments) - 1):\n",
    "    exp_name = experiments[idx_exp + 1]\n",
    "    print(\"Experiment:\", exp_name)\n",
    "\n",
    "    # bias[:, idx_exp, :].shape -> (n_region_season, n_models)\n",
    "    # transpose -> (n_models, n_region_season)\n",
    "    df = pd.DataFrame(\n",
    "        data=bias[:, idx_exp, :].transpose(),\n",
    "        index=models,\n",
    "        columns=region_season_label\n",
    "    )\n",
    "\n",
    "    # Reshape df to \"long\" format with columns [Model, region_season_label, value]\n",
    "    df_long = df.reset_index().melt(\n",
    "        id_vars=\"index\",                 # \"index\" column is the model\n",
    "        var_name=\"RegionSeason\",         # name for the melted columns\n",
    "        value_name=\"Bias\"               # name for the melted values\n",
    "    )\n",
    "\n",
    "    # Rename \"index\" -> \"Model\"\n",
    "    df_long.rename(columns={\"index\": \"Model\"}, inplace=True)\n",
    "\n",
    "    # Add a column for Experiment\n",
    "    df_long[\"Experiment\"] = exp_name\n",
    "\n",
    "    # Append to the list\n",
    "    all_data.append(df_long)\n",
    "\n",
    "# Concatenate all experiments into one DataFrame\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Optionally reorder columns (Experiment, Model, RegionSeason, Bias)\n",
    "final_df = final_df[[\"Experiment\", \"Model\", \"RegionSeason\", \"Bias\"]]\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv(\"all_bias_results.csv\", index=False)\n",
    "\n",
    "print(\"CSV file saved: all_bias_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdbdfa0-90be-4657-89e8-84e2dafd6ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
